---
layout: home
---
<h2> Hello everyone!<br><br></h2>

<!-- (Scroll down the page to see the Chinese version 後面有中文版本)<br><br> -->

I am Jun-You Wang (王鈞右), a post-doctoral researcher at the <a href="https://sites.google.com/view/mctl/home/">Music and Culture Technology Lab</a>, <a href="https://iis.sinica.edu.tw/">Institude of Information Science</a>, <a href="https://www.sinica.edu.tw/">Academia Sinica</a>.<br><br>

My research focuses on enhancing human's <b>music experience</b> through the use of computational tools such as Deep Neural Networks (DNNs). As a person who loves music and (perhaps with some exaggeration) was saved by music during my teenage years, it is a great pleasure to contribute to the development of future music culture with my knowledge and experiences in computer science, particularly in machine learning and data science.<br><br>

My research goal is to <b>make it much easier for people with different backgrounds to understand, appreciate, interact with, and even create, the type of music they like.</b> Take myself as an example. I do not have a background in music/musicology and cannot really appreciate music with in-depth analysis. From my perspective, it would be great to have a computational tool that tells me <i>how</i> does a musical piece make me feel nostalgic, or <i>what</i> makes the performance of a singer distinguished compared with others'. It would also be great to have a computational tool that helps me create my own music in a much easier way, while still allowing me to express my own thought and/or feeling.<br><br>

These ideas lead to my three research directions! <br><br>

<h3>Music signal analysis<br><br></h3>
I develop models that analyze music signal automatically. My previous work in this direction includes singing (note) transcription (<a href="https://ieeexplore.ieee.org/abstract/document/9414601/">ICASSP 2021</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9961922/">IEEE/ACM TASLP 2023</a>), automatic lyrics transcription and lyrics(-to-audio) alignment (<a href="https://ieeexplore.ieee.org/abstract/document/10389800/">ASRU 2023</a>, <a href="https://ieeexplore.ieee.org/abstract/document/10447561/">ICASSP 2024</a>). The advancements on these tasks pave the way for future research on music signal analysis of higher-level concepts.<br><br>

These tasks lead to practical applications such as automatic karaoke content generation, which requires time-aligned lyrics and (possibly) note transcription.<br>

<h3>Symbolic music understanding<br><br></h3>
I also work on developing models that can automatically analyze and understand high-level concepts of symbolic music (e.g., MIDI files, sheet music). My recent works along this direction are now under peer review. Hopefully they will be published.<br>

<h3>Music synthesis<br><br></h3>
I also work on music synthesis tasks such as singing voice synthesis (<a href=https://ieeexplore.ieee.org/abstract/document/10389711/>ASRU 2023</a>) and singing performance style transfer (<a href=https://ieeexplore.ieee.org/abstract/document/10767407/>IEEE SPL 2025</a>). I hope that in the future, we can have a music synthesis system that does not only generate <b>natural</b> music performance, but also generate <b>expressive</b> music performance which can be controlled or specified by human users freely and easily. This means we have to develop a system that can synthesize audio with a wide range of style/expressiveness (sometimes even goes beyond the actual singing/instruments), while also ensuring that such a system is <b>highly controllable</b>. I believe that such a system could change the digital music production in the future.<br><br>

=======

<h2>Working experiences</h2>
<ul>
  <li>Post-doctoral researcher, Music and Culture Technology Lab, Institude of Information Science, Academia Sinica (Aug. 2024 &ndash; )</li>
</ul>
<br><br>

<h2>Education experiences</h2>
<ul>
  <li>Ph.D., Department of Computer Science and Information Engineering, National Taiwan University (Sep. 2021 &ndash; Jun. 2024)<br>
  	Advisor: <a href="http://mirlab.org/jang/">Prof. Jyh-Shing Roger Jang</a>; Lab: <a href="http://mirlab.org/">Multimedia Information Retrieval lab (MIRLAB)</a></li><br>
  <li>B.S., Department of Computer Science and Information Engineering, National Taiwan University (Sep. 2017 &ndash; Jun. 2021)</li>
</ul>